<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-models/top-models" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Essential Models for Mac | Mac AI Pilot</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://ETpkAI.github.io/mac-ai-hub/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://ETpkAI.github.io/mac-ai-hub/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://ETpkAI.github.io/mac-ai-hub/docs/models/top-models"><meta data-rh="true" property="og:locale" content="en_US"><meta data-rh="true" property="og:locale:alternate" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Essential Models for Mac | Mac AI Pilot"><meta data-rh="true" name="description" content="A curated list of the best large language models optimized for Apple Silicon. All recommendations are in GGUF format for maximum compatibility."><meta data-rh="true" property="og:description" content="A curated list of the best large language models optimized for Apple Silicon. All recommendations are in GGUF format for maximum compatibility."><link data-rh="true" rel="icon" href="/mac-ai-hub/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://ETpkAI.github.io/mac-ai-hub/docs/models/top-models"><link data-rh="true" rel="alternate" href="https://ETpkAI.github.io/mac-ai-hub/docs/models/top-models" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://ETpkAI.github.io/mac-ai-hub/zh-Hans/docs/models/top-models" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://ETpkAI.github.io/mac-ai-hub/docs/models/top-models" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Model Vault","item":"https://ETpkAI.github.io/mac-ai-hub/docs/category/model-vault"},{"@type":"ListItem","position":2,"name":"Top Models","item":"https://ETpkAI.github.io/mac-ai-hub/docs/models/top-models"}]}</script><link rel="alternate" type="application/rss+xml" href="/mac-ai-hub/blog/rss.xml" title="Mac AI Pilot RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mac-ai-hub/blog/atom.xml" title="Mac AI Pilot Atom Feed"><link rel="stylesheet" href="/mac-ai-hub/assets/css/styles.6fa0cf75.css">
<script src="/mac-ai-hub/assets/js/runtime~main.204244e4.js" defer="defer"></script>
<script src="/mac-ai-hub/assets/js/main.e55c9135.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/mac-ai-hub/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/mac-ai-hub/"><div class="navbar__logo"><img src="/mac-ai-hub/img/logo.svg" alt="Mac AI Pilot Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/mac-ai-hub/img/logo.svg" alt="Mac AI Pilot Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Mac AI Pilot</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/mac-ai-hub/docs/intro">Start Here</a><a class="navbar__item navbar__link" href="/mac-ai-hub/docs/models/gguf-basics">Model Vault</a><a class="navbar__item navbar__link" href="/mac-ai-hub/docs/apps/setup-guide">App Lab</a><a class="navbar__item navbar__link" href="/mac-ai-hub/blog">Workflows</a><a class="navbar__item navbar__link" href="/mac-ai-hub/docs/ai-news">AI News</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/ETpkAI/mac-ai-hub" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/mac-ai-hub/docs/models/top-models" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en-US">English</a></li><li><a href="/mac-ai-hub/zh-Hans/docs/models/top-models" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-Hans">ÁÆÄ‰Ωì‰∏≠Êñá</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/mac-ai-hub/docs/intro"><span title="Welcome to Mac AI Pilot" class="linkLabel_WmDU">Welcome to Mac AI Pilot</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/mac-ai-hub/docs/category/app-guides"><span title="App Guides" class="categoryLinkLabel_W154">App Guides</span></a><button aria-label="Expand sidebar category &#x27;App Guides&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/mac-ai-hub/docs/category/model-vault"><span title="Model Vault" class="categoryLinkLabel_W154">Model Vault</span></a><button aria-label="Collapse sidebar category &#x27;Model Vault&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/mac-ai-hub/docs/models/gguf-basics"><span title="GGUF Basics" class="linkLabel_WmDU">GGUF Basics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/mac-ai-hub/docs/models/top-models"><span title="Top Models" class="linkLabel_WmDU">Top Models</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/mac-ai-hub/docs/ai-news/"><span title="ÊØèÊó• AI Êñ∞Èóª" class="categoryLinkLabel_W154">ÊØèÊó• AI Êñ∞Èóª</span></a><button aria-label="Expand sidebar category &#x27;ÊØèÊó• AI Êñ∞Èóª&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/mac-ai-hub/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/mac-ai-hub/docs/category/model-vault"><span>Model Vault</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Top Models</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Essential Models for Mac</h1></header>
<p>A curated list of the best large language models optimized for Apple Silicon. All recommendations are in GGUF format for maximum compatibility.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="quick-reference-table">Quick Reference Table<a href="#quick-reference-table" class="hash-link" aria-label="Direct link to Quick Reference Table" title="Direct link to Quick Reference Table" translate="no">‚Äã</a></h2>
<table><thead><tr><th>Model</th><th>Parameters</th><th>Min RAM</th><th>Recommended Quant</th><th>Best For</th><th>Download</th></tr></thead><tbody><tr><td><strong>Llama 3.1 8B</strong></td><td>8B</td><td>8GB</td><td>Q4_K_M</td><td>General chat, coding</td><td><a href="https://huggingface.co/meta-llama" target="_blank" rel="noopener noreferrer" class="">HuggingFace</a></td></tr><tr><td><strong>Mistral 7B</strong></td><td>7B</td><td>8GB</td><td>Q4_K_M</td><td>Fast responses, instruction-following</td><td><a href="https://huggingface.co/mistralai" target="_blank" rel="noopener noreferrer" class="">HuggingFace</a></td></tr><tr><td><strong>Gemma 2 9B</strong></td><td>9B</td><td>10GB</td><td>Q4_K_M</td><td>Balanced performance</td><td><a href="https://huggingface.co/google" target="_blank" rel="noopener noreferrer" class="">HuggingFace</a></td></tr><tr><td><strong>Llama 3.1 70B</strong></td><td>70B</td><td>48GB</td><td>Q4_K_M</td><td>Advanced reasoning</td><td><a href="https://huggingface.co/meta-llama" target="_blank" rel="noopener noreferrer" class="">HuggingFace</a></td></tr><tr><td><strong>Qwen 2.5 32B</strong></td><td>32B</td><td>24GB</td><td>Q4_K_M</td><td>Multilingual, coding</td><td><a href="https://huggingface.co/Qwen" target="_blank" rel="noopener noreferrer" class="">HuggingFace</a></td></tr><tr><td><strong>DeepSeek Coder</strong></td><td>33B</td><td>24GB</td><td>Q4_K_M</td><td>Code generation</td><td><a href="https://huggingface.co/deepseek-ai" target="_blank" rel="noopener noreferrer" class="">HuggingFace</a></td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="detailed-recommendations">Detailed Recommendations<a href="#detailed-recommendations" class="hash-link" aria-label="Direct link to Detailed Recommendations" title="Direct link to Detailed Recommendations" translate="no">‚Äã</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="-for-8gb-macs-m1m2m3-base">ü•á For 8GB Macs (M1/M2/M3 Base)<a href="#-for-8gb-macs-m1m2m3-base" class="hash-link" aria-label="Direct link to ü•á For 8GB Macs (M1/M2/M3 Base)" title="Direct link to ü•á For 8GB Macs (M1/M2/M3 Base)" translate="no">‚Äã</a></h3>
<p>Your options are limited but still powerful:</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="llama-31-8b-instruct">Llama 3.1 8B Instruct<a href="#llama-31-8b-instruct" class="hash-link" aria-label="Direct link to Llama 3.1 8B Instruct" title="Direct link to Llama 3.1 8B Instruct" translate="no">‚Äã</a></h4>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">File: Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Size: ~4.9GB</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Speed: ~15-20 tokens/sec</span><br></span></code></pre></div></div>
<p><strong>Pros:</strong></p>
<ul>
<li class="">Excellent instruction following</li>
<li class="">Strong coding capabilities</li>
<li class="">Great at reasoning tasks</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li class="">8B limit means less knowledge depth</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Memory Tip</div><div class="admonitionContent_BuS1"><p>Close Safari and other apps before running. Every GB counts on 8GB machines!</p></div></div>
<hr>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="mistral-7b-instruct-v03">Mistral 7B Instruct v0.3<a href="#mistral-7b-instruct-v03" class="hash-link" aria-label="Direct link to Mistral 7B Instruct v0.3" title="Direct link to Mistral 7B Instruct v0.3" translate="no">‚Äã</a></h4>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">File: Mistral-7B-Instruct-v0.3-Q4_K_M.gguf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Size: ~4.4GB</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Speed: ~20-25 tokens/sec</span><br></span></code></pre></div></div>
<p><strong>Pros:</strong></p>
<ul>
<li class="">Fastest 7B model</li>
<li class="">Excellent at following instructions</li>
<li class="">Lower memory usage</li>
</ul>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="-for-16-18gb-macs-m2m3-pro">ü•à For 16-18GB Macs (M2/M3 Pro)<a href="#-for-16-18gb-macs-m2m3-pro" class="hash-link" aria-label="Direct link to ü•à For 16-18GB Macs (M2/M3 Pro)" title="Direct link to ü•à For 16-18GB Macs (M2/M3 Pro)" translate="no">‚Äã</a></h3>
<p>You can run medium-sized models comfortably:</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="gemma-2-9b-instruct">Gemma 2 9B Instruct<a href="#gemma-2-9b-instruct" class="hash-link" aria-label="Direct link to Gemma 2 9B Instruct" title="Direct link to Gemma 2 9B Instruct" translate="no">‚Äã</a></h4>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">File: gemma-2-9b-it-Q5_K_M.gguf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Size: ~6.5GB</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Speed: ~12-18 tokens/sec</span><br></span></code></pre></div></div>
<p><strong>Pros:</strong></p>
<ul>
<li class="">Google&#x27;s latest architecture</li>
<li class="">Excellent at nuanced responses</li>
<li class="">Strong multilingual support</li>
</ul>
<hr>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="qwen-25-14b-instruct">Qwen 2.5 14B Instruct<a href="#qwen-25-14b-instruct" class="hash-link" aria-label="Direct link to Qwen 2.5 14B Instruct" title="Direct link to Qwen 2.5 14B Instruct" translate="no">‚Äã</a></h4>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">File: Qwen2.5-14B-Instruct-Q4_K_M.gguf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Size: ~8.5GB</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Speed: ~10-15 tokens/sec</span><br></span></code></pre></div></div>
<p><strong>Pros:</strong></p>
<ul>
<li class="">Excellent for Chinese + English</li>
<li class="">Strong coding abilities</li>
<li class="">Great general knowledge</li>
</ul>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="-for-32-64gb-macs-m2m3-max">ü•á For 32-64GB Macs (M2/M3 Max)<a href="#-for-32-64gb-macs-m2m3-max" class="hash-link" aria-label="Direct link to ü•á For 32-64GB Macs (M2/M3 Max)" title="Direct link to ü•á For 32-64GB Macs (M2/M3 Max)" translate="no">‚Äã</a></h3>
<p>Access to powerful large models:</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="llama-31-70b-instruct">Llama 3.1 70B Instruct<a href="#llama-31-70b-instruct" class="hash-link" aria-label="Direct link to Llama 3.1 70B Instruct" title="Direct link to Llama 3.1 70B Instruct" translate="no">‚Äã</a></h4>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">File: Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Size: ~40GB</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Speed: ~8-12 tokens/sec</span><br></span></code></pre></div></div>
<p><strong>Pros:</strong></p>
<ul>
<li class="">Near GPT-4 quality</li>
<li class="">Exceptional reasoning</li>
<li class="">Comprehensive knowledge</li>
</ul>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Requires 48GB+ RAM</div><div class="admonitionContent_BuS1"><p>70B models need significant memory. Use Q4_K_M quantization and close all other apps.</p></div></div>
<hr>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="qwen-25-32b-instruct">Qwen 2.5 32B Instruct<a href="#qwen-25-32b-instruct" class="hash-link" aria-label="Direct link to Qwen 2.5 32B Instruct" title="Direct link to Qwen 2.5 32B Instruct" translate="no">‚Äã</a></h4>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">File: Qwen2.5-32B-Instruct-Q4_K_M.gguf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Size: ~19GB</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Speed: ~12-16 tokens/sec</span><br></span></code></pre></div></div>
<p><strong>Pros:</strong></p>
<ul>
<li class="">Best-in-class for 32B size</li>
<li class="">Excellent coding</li>
<li class="">Fast for its size</li>
</ul>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="-for-coding-specifically">üíª For Coding Specifically<a href="#-for-coding-specifically" class="hash-link" aria-label="Direct link to üíª For Coding Specifically" title="Direct link to üíª For Coding Specifically" translate="no">‚Äã</a></h3>
<table><thead><tr><th>Model</th><th>Parameters</th><th>Specialty</th></tr></thead><tbody><tr><td><strong>DeepSeek Coder V2</strong></td><td>16B</td><td>General coding</td></tr><tr><td><strong>CodeLlama 34B</strong></td><td>34B</td><td>Python, JavaScript</td></tr><tr><td><strong>Qwen 2.5 Coder</strong></td><td>7B-32B</td><td>Multi-language</td></tr><tr><td><strong>StarCoder2</strong></td><td>15B</td><td>Multi-language</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Coding Model Tips</div><div class="admonitionContent_BuS1"><ul>
<li class="">Use Q5_K_M or Q8_0 for code‚Äîprecision matters for syntax</li>
<li class="">Increase context length for larger codebases</li>
<li class="">Consider models fine-tuned for your language</li>
</ul></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-to-download">How to Download<a href="#how-to-download" class="hash-link" aria-label="Direct link to How to Download" title="Direct link to How to Download" translate="no">‚Äã</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="using-ollama-easiest">Using Ollama (Easiest)<a href="#using-ollama-easiest" class="hash-link" aria-label="Direct link to Using Ollama (Easiest)" title="Direct link to Using Ollama (Easiest)" translate="no">‚Äã</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">ollama pull llama3.1:8b</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ollama pull mistral:7b</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ollama pull gemma2:9b</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="direct-from-huggingface">Direct from HuggingFace<a href="#direct-from-huggingface" class="hash-link" aria-label="Direct link to Direct from HuggingFace" title="Direct link to Direct from HuggingFace" translate="no">‚Äã</a></h3>
<ol>
<li class="">Visit <a href="https://huggingface.co" target="_blank" rel="noopener noreferrer" class="">huggingface.co</a></li>
<li class="">Search for the model</li>
<li class="">Go to <strong>Files and versions</strong></li>
<li class="">Download the <code>.gguf</code> file matching your RAM</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="using-huggingface-cli">Using <code>huggingface-cli</code><a href="#using-huggingface-cli" class="hash-link" aria-label="Direct link to using-huggingface-cli" title="Direct link to using-huggingface-cli" translate="no">‚Äã</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install huggingface_hub</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">huggingface-cli download TheBloke/Llama-2-7B-GGUF llama-2-7b.Q4_K_M.gguf</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="performance-expectations">Performance Expectations<a href="#performance-expectations" class="hash-link" aria-label="Direct link to Performance Expectations" title="Direct link to Performance Expectations" translate="no">‚Äã</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="tokens-per-second-by-hardware">Tokens per Second by Hardware<a href="#tokens-per-second-by-hardware" class="hash-link" aria-label="Direct link to Tokens per Second by Hardware" title="Direct link to Tokens per Second by Hardware" translate="no">‚Äã</a></h3>
<table><thead><tr><th>Hardware</th><th>7B Model</th><th>13B Model</th><th>70B Model</th></tr></thead><tbody><tr><td>M1 8GB</td><td>15-20 t/s</td><td>‚ùå</td><td>‚ùå</td></tr><tr><td>M2 Pro 16GB</td><td>20-25 t/s</td><td>12-18 t/s</td><td>‚ùå</td></tr><tr><td>M3 Max 64GB</td><td>25-30 t/s</td><td>18-22 t/s</td><td>8-12 t/s</td></tr><tr><td>M2 Ultra 192GB</td><td>30+ t/s</td><td>22-28 t/s</td><td>15-20 t/s</td></tr></tbody></table>
<hr>
<p><strong>Previous:</strong> <a class="" href="/mac-ai-hub/docs/models/gguf-basics">GGUF Basics</a> - Understanding quantization and memory requirements</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/mac-ai-hub/docs/models/gguf-basics"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">GGUF Basics</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/mac-ai-hub/docs/ai-news/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">ÊØèÊó• AI Êñ∞Èóª TOP10</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#quick-reference-table" class="table-of-contents__link toc-highlight">Quick Reference Table</a></li><li><a href="#detailed-recommendations" class="table-of-contents__link toc-highlight">Detailed Recommendations</a><ul><li><a href="#-for-8gb-macs-m1m2m3-base" class="table-of-contents__link toc-highlight">ü•á For 8GB Macs (M1/M2/M3 Base)</a></li><li><a href="#-for-16-18gb-macs-m2m3-pro" class="table-of-contents__link toc-highlight">ü•à For 16-18GB Macs (M2/M3 Pro)</a></li><li><a href="#-for-32-64gb-macs-m2m3-max" class="table-of-contents__link toc-highlight">ü•á For 32-64GB Macs (M2/M3 Max)</a></li><li><a href="#-for-coding-specifically" class="table-of-contents__link toc-highlight">üíª For Coding Specifically</a></li></ul></li><li><a href="#how-to-download" class="table-of-contents__link toc-highlight">How to Download</a><ul><li><a href="#using-ollama-easiest" class="table-of-contents__link toc-highlight">Using Ollama (Easiest)</a></li><li><a href="#direct-from-huggingface" class="table-of-contents__link toc-highlight">Direct from HuggingFace</a></li><li><a href="#using-huggingface-cli" class="table-of-contents__link toc-highlight">Using <code>huggingface-cli</code></a></li></ul></li><li><a href="#performance-expectations" class="table-of-contents__link toc-highlight">Performance Expectations</a><ul><li><a href="#tokens-per-second-by-hardware" class="table-of-contents__link toc-highlight">Tokens per Second by Hardware</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Learning</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/mac-ai-hub/docs/intro">Start Here</a></li><li class="footer__item"><a class="footer__link-item" href="/mac-ai-hub/docs/apps/setup-guide">App Guides</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/mac-ai-hub/docs/models/gguf-basics">Model Vault</a></li><li class="footer__item"><a class="footer__link-item" href="/mac-ai-hub/blog">Workflows</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/ETpkAI/mac-ai-hub" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2026 Mac AI Pilot. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>